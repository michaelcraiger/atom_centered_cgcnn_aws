{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "multiple functions taken from https://github.com/txie-93/cgcnn/blob/master/cgcnn/data.py\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import csv\n",
    "import functools\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from pymatgen.core.structure import Structure\n",
    "\n",
    "\n",
    "class GaussianDistance(object):\n",
    "    \"\"\"\n",
    "    Expands the distance by Gaussian basis.\n",
    "\n",
    "    Unit: angstrom\n",
    "    \"\"\"\n",
    "    def __init__(self, dmin, dmax, step, var=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        dmin: float\n",
    "          Minimum interatomic distance\n",
    "        dmax: float\n",
    "          Maximum interatomic distance\n",
    "        step: float\n",
    "          Step size for the Gaussian filter\n",
    "        \"\"\"\n",
    "        assert dmin < dmax\n",
    "        assert dmax - dmin > step\n",
    "        self.filter = np.arange(dmin, dmax+step, step)\n",
    "        if var is None:\n",
    "            var = step\n",
    "        self.var = var\n",
    "\n",
    "    def expand(self, distances):\n",
    "        \"\"\"\n",
    "        Apply Gaussian disntance filter to a numpy distance array\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        distance: np.array shape n-d array\n",
    "          A distance matrix of any shape\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        expanded_distance: shape (n+1)-d array\n",
    "          Expanded distance matrix with the last dimension of length\n",
    "          len(self.filter)\n",
    "        \"\"\"\n",
    "        return np.exp(-(distances[..., np.newaxis] - self.filter)**2 /\n",
    "                      self.var**2)\n",
    "\n",
    "\n",
    "class AtomInitializer(object):\n",
    "    \"\"\"\n",
    "    Base class for intializing the vector representation for atoms.\n",
    "\n",
    "    !!! Use one AtomInitializer per dataset !!!\n",
    "    \"\"\"\n",
    "    def __init__(self, atom_types):\n",
    "        self.atom_types = set(atom_types)\n",
    "        self._embedding = {}\n",
    "\n",
    "    def get_atom_fea(self, atom_type):\n",
    "        assert atom_type in self.atom_types\n",
    "        return self._embedding[atom_type]\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self._embedding = state_dict\n",
    "        self.atom_types = set(self._embedding.keys())\n",
    "        self._decodedict = {idx: atom_type for atom_type, idx in\n",
    "                            self._embedding.items()}\n",
    "\n",
    "    def state_dict(self):\n",
    "        return self._embedding\n",
    "\n",
    "    def decode(self, idx):\n",
    "        if not hasattr(self, '_decodedict'):\n",
    "            self._decodedict = {idx: atom_type for atom_type, idx in\n",
    "                                self._embedding.items()}\n",
    "        return self._decodedict[idx]\n",
    "\n",
    "\n",
    "class AtomCustomJSONInitializer(AtomInitializer):\n",
    "    \"\"\"\n",
    "    Initialize atom feature vectors using a JSON file, which is a python\n",
    "    dictionary mapping from element number to a list representing the\n",
    "    feature vector of the element.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    elem_embedding_file: str\n",
    "        The path to the .json file\n",
    "    \"\"\"\n",
    "    def __init__(self, elem_embedding_file):\n",
    "        with open(elem_embedding_file) as f:\n",
    "            elem_embedding = json.load(f)\n",
    "        elem_embedding = {int(key): value for key, value\n",
    "                          in elem_embedding.items()}\n",
    "        atom_types = set(elem_embedding.keys())\n",
    "        super(AtomCustomJSONInitializer, self).__init__(atom_types)\n",
    "        for key, value in elem_embedding.items():\n",
    "            self._embedding[key] = np.array(value, dtype=float)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makedir_if_not_exist(dir_to_make):\n",
    "    if not os.path.exists(dir_to_make):\n",
    "        os.makedirs(dir_to_make)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_dset(savedir, root_dir, max_num_nbr=6, radius=8, dmin=0, step=0.2,\n",
    "             random_seed=123):\n",
    "    \"\"\"\n",
    "    The pickle_dset reads the relevant data for a given param set, so can be used in aws (no need to install pymatgen):\n",
    "\n",
    "    inputs as in https://github.com/txie-93/\n",
    "    root_dir\n",
    "    ├── id_prop.csv\n",
    "    ├── atom_init.json\n",
    "    ├── id0.cif\n",
    "    ├── id1.cif\n",
    "    ├── ...\n",
    "\n",
    "    id_prop.csv: a CSV file with two columns. The first column recodes a\n",
    "    unique ID for each crystal, and the second column recodes the value of\n",
    "    target property.\n",
    "\n",
    "    atom_init.json: a JSON file that stores the initialization vector for each\n",
    "    element.\n",
    "\n",
    "    ID.cif: a CIF file that recodes the crystal structure, where ID is the\n",
    "    unique ID for the crystal.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    savedir: str\n",
    "        The path to the directory we will create which will contain the datasets to be passed into AWS.\n",
    "    root_dir: str\n",
    "        The path to the root directory of the dataset with atom_init.json and id_prop.csv\n",
    "    max_num_nbr: int\n",
    "        The maximum number of neighbors while constructing the crystal graph\n",
    "    radius: float\n",
    "        The cutoff radius for searching neighbors\n",
    "    dmin: float\n",
    "        The minimum distance for constructing GaussianDistance\n",
    "    step: float\n",
    "        The step size for constructing GaussianDistance\n",
    "    random_seed: int\n",
    "        Random seed for shuffling the dataset\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    nothing, just pickles\n",
    "    \"\"\"\n",
    "\n",
    "    root_dir = root_dir\n",
    "    max_num_nbr, radius = max_num_nbr, radius\n",
    "    assert os.path.exists(root_dir), 'root_dir does not exist!'   \n",
    "    \n",
    "    makedir_if_not_exist(savedir)\n",
    "    makedir_if_not_exist(savedir+\"/atom_feas\")\n",
    "    makedir_if_not_exist(savedir+\"/nbr_feas\")\n",
    "    makedir_if_not_exist(savedir+\"/nbr_fea_indices\")\n",
    "    makedir_if_not_exist(savedir+\"/rel_indices\")\n",
    "    makedir_if_not_exist(savedir+\"/cif_ids\")\n",
    "    makedir_if_not_exist(savedir+\"/targets\")\n",
    "\n",
    "    assert os.path.exists(savedir), 'pickling directory savedir does not exist!'\n",
    "\n",
    "    id_prop_file = os.path.join(root_dir, 'id_prop.csv')\n",
    "    assert os.path.exists(id_prop_file), 'id_prop.csv does not exist!'\n",
    "    with open(id_prop_file) as f:\n",
    "        reader = csv.reader(f)\n",
    "        id_prop_data = [row for row in reader]\n",
    "\n",
    "    random.seed(random_seed)\n",
    "    random.shuffle(id_prop_data)\n",
    "    atom_init_file = os.path.join(root_dir, 'atom_init.json')\n",
    "    assert os.path.exists(atom_init_file), 'atom_init.json does not exist!'\n",
    "    ari = AtomCustomJSONInitializer(atom_init_file)\n",
    "    gdf = GaussianDistance(dmin=dmin, dmax=radius, step=step)\n",
    "\n",
    "    # pickle objects in initialization instead of by\n",
    "    # csv and pymatgen .. can use in cloud then\n",
    "\n",
    "    count = 0\n",
    "    for cif_id, target, o_atom_idx, _ in id_prop_data:\n",
    "        if count%1000==0:\n",
    "            print(count)\n",
    "        crystal = Structure.from_file(os.path.join(root_dir,\n",
    "                                                   cif_id+'.cif'))\n",
    "        o_nbr_dist = 3\n",
    "        o_atom_nbrs = crystal.get_neighbors(crystal[int(o_atom_idx)], o_nbr_dist)\n",
    "        max_o_nbrs = 6\n",
    "        o_dists = []\n",
    "        for site in o_atom_nbrs:\n",
    "            o_dists.append(site[1])\n",
    "        o_nbr_indices = sorted(range(len(o_dists)), key=lambda k: o_dists[k])\n",
    "        o_nbr_indices = np.array(o_nbr_indices[:max_o_nbrs])\n",
    "        # pymatgen returns indices outside the actual crystal len (images)\n",
    "        # so here we handle any time that happens . TO DO: handle better!\n",
    "        # we are paddin with the O centered atom\n",
    "        o_nbr_indices[o_nbr_indices > len(crystal)-1] = o_atom_idx\n",
    "        o_nbr_indices = list(o_nbr_indices)\n",
    "        rel_inds = [int(o_atom_idx)]\n",
    "        rel_inds += o_nbr_indices\n",
    "\n",
    "        atom_fea = np.vstack([ari.get_atom_fea(crystal[i].specie.number)\n",
    "                              for i in range(len(crystal))])\n",
    "        atom_fea = torch.Tensor(atom_fea)\n",
    "        all_nbrs = crystal.get_all_neighbors(radius, include_index=True)\n",
    "        all_nbrs = [sorted(nbrs, key=lambda x: x[1]) for nbrs in all_nbrs]\n",
    "        nbr_fea_idx, nbr_fea = [], []\n",
    "        for nbr in all_nbrs:\n",
    "            if len(nbr) < max_num_nbr:\n",
    "                warnings.warn('{} not find enough neighbors to build graph. '\n",
    "                              'If it happens frequently, consider increase '\n",
    "                              'radius.'.format(cif_id))\n",
    "                nbr_fea_idx.append(list(map(lambda x: x[2], nbr)) +\n",
    "                                   [0] * (max_num_nbr - len(nbr)))\n",
    "                nbr_fea.append(list(map(lambda x: x[1], nbr)) +\n",
    "                               [radius + 1.] * (max_num_nbr -\n",
    "                                                     len(nbr)))\n",
    "            else:\n",
    "                nbr_fea_idx.append(list(map(lambda x: x[2],\n",
    "                                            nbr[:max_num_nbr])))\n",
    "                nbr_fea.append(list(map(lambda x: x[1],\n",
    "                                        nbr[:max_num_nbr])))\n",
    "        nbr_fea_idx, nbr_fea = np.array(nbr_fea_idx), np.array(nbr_fea)\n",
    "        nbr_fea = gdf.expand(nbr_fea)\n",
    "        atom_fea = torch.Tensor(atom_fea)\n",
    "        nbr_fea = torch.Tensor(nbr_fea)\n",
    "        nbr_fea_idx = torch.LongTensor(nbr_fea_idx)\n",
    "        target = torch.Tensor([float(target)])\n",
    "\n",
    "        for val in o_nbr_indices:\n",
    "            if val>=len(crystal):\n",
    "                print(o_atom_idx)\n",
    "                print(cif_id)\n",
    "                print(len(crystal))\n",
    "                print(o_nbr_indices)\n",
    "                \n",
    "        pickle.dump(atom_fea, open(\"{}/atom_feas/atom_fea_{}.p\".format(savedir, count), \"wb\"))\n",
    "        pickle.dump(target, open(\"{}/targets/target_{}.p\".format(savedir, count), \"wb\"))\n",
    "        pickle.dump(cif_id, open(\"{}/cif_ids/cif_id_{}.p\".format(savedir, count), \"wb\"))\n",
    "        pickle.dump(nbr_fea, open(\"{}/nbr_feas/nbr_fea_{}.p\".format(savedir, count), \"wb\"))\n",
    "        pickle.dump(nbr_fea_idx, open(\"{}/nbr_fea_indices/nbr_fea_idx_{}.p\".format(savedir, count), \"wb\"))\n",
    "        pickle.dump(rel_inds, open(\"{}/rel_indices/rel_index_{}.p\".format(savedir, count), \"wb\"))\n",
    "        count+=1\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run the code as pickle_dset(pickle_dir, data_dir)\n",
    "data_dir contains the directory with structure as in the cgcnn example data directory, with cif id, atom_init.json and id_prop.csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optuna_cgcnn",
   "language": "python",
   "name": "optuna_cgcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
